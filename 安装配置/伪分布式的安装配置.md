---
title: 伪分布式的安装配置
zhihu-url: https://zhuanlan.zhihu.com/p/491426016
注意: 所有的冒号是半角冒号，冒号后面有一个半角空格
---

# 伪分布式的安装配置

## 前提准备

### openVPN（内网需要）

* 先下载open VPN
* 再导入提供的配置文件，等连接成功（图标变绿）

### mobaXterm
* 进入查看环境中master节点的ip地址和root账号密码
* 通过mobaXterm工具ssh连接上master节点
* 将下载好的Hadoop 2.9.2压缩包和jdk压缩包放到home目录下
* 通过命令将Hadoop和jdk解压到根目录的opt目录下

### 配置环境变量
* 通过如下命令配置jdk

```sh
# 进入编辑文件
vi /etc/profile

# 在配置文件末尾添加如下配置
# JAVA的环境变量配置
export JAVA_HOME=/opt/jdk1.8.0_112
export JRE_HOME=/opt/jdk1.8.0_112/jre
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 

# Hadoop环境变量配置
export HADOOP_HOME=/opt/hadoop-2.9.2 
export PATH=${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:$PATH 
```

使配置文件生效
```sh
source /etc/profile
```

## 配置Hadoop 
hadoop的配置文件在`/opt/hadoop2.9.0/etc/hadoop/`目录下

### hadoop-env.sh和yarn-env.sh

配置JAVA环境变量

```sh
JAVA_HOME=${JAVA_HOME}
```

### 配置core-site.xml文件
指定HDFS的 NameNode的地址，value值是主机名加端口号（不变），主机使用master节点的ip地址

```xml
vi core-site.xml

# ipaddr是主机的ip地址（自行更改）
# 在<configuration>标签中添加
<property>
	<name>fs.default.name</name>
	<value>hdfs://ipaddr:9000</value>
</property> 

<property>
	<name>fs.defaultFS</name>
	<value>hdfs://ipaddr:9000</value>
 </property>
 <!-- 存储文件的路径 -->
<property>
	<name>hadoop.tmp.dir</name>
	<value>/home/hadooptmp</value>
 </property> 
```

* 配置hdfs-site.xml，指定hdfs保存数据的副本数量，伪分布式只有一个节点，所以这里填：1

```xml
vi hdfs-site.xml

# 在<configuration>标签下
<property>
	<name>dfs.replication</name>
	<value>1</value>
</property>
<property>
	<name>dfs.name.dir</name>
	<value>/home/hadoopname</value>
</property>
<property>
	<name>dfs.data.dir</name>
	<value>/home/hadoopdata</value>
 </property>
```

* 配置 mapred-site.xml：原本hadoop文件夹的etc下是没有mapred-site.xml,通过命令创建

```xml
mv mapred-site.xml.template mapred-site.xml
vi mapred-site.xml
#添加以下内容：
<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
</property> 
```

* 添加两个属性，第一个告诉nodemanager获取数据的方式为shuffle：

```xml
vi yarn-site.xml

<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
</property>
<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>master</value>
</property>
```

### 设置免密登录

```sh
# 进入root
cd /root
# 一般使没有.ssh目录的，需要自己登录一次
ssh master
# 配置，会出现多条提示（回车就行）
cd .ssh
ssh-keygen -t rsa
cat id_rsa.pub >> authorized_keys 
# 配置完成，测试 ssh master不会提示输入密码
ssh master
```

### 开始初始化

```sh
# 在以下文件中输入如下命令
cd /opt/hadoop-2.9.2/etc/hadoop/
# 格式化
hadoop namenode -format

# 测试hdfs
cd /opt/hadoop-2.9.2/sbin/
# 启动所有
./start-all.sh
# 或者
./start-dfs.sh
./start-yarn.sh

# 测试命令
hadoop fs -ls /         # 初次建立没有任何文件
hadoop fs -mkdir /test  # 建立test目录
hadoop fs -ls /         # 此时显示有test目录
```



### 判断hadoop伪分布式搭建是否成功的2个方法：
* 方法一：命令行下输入 jps 回车，显示6个进程
* 方法二： 
* start-all.cmd   启动hadoop成功后，有2个web访问界面能成功访问，下面IP替换为自己的master实验虚拟机的IP
    * `master:50070`  50070端口节点文件管理界面： 可查看节点(3)，文件(7-1)
    * `master:8088/`     8088端口yarn资源管理界面