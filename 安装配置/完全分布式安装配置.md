---
title: 完全分布式安装配置
zhihu-url: https://zhuanlan.zhihu.com/p/491287061
注意: 所有的冒号是半角冒号，冒号后面有一个半角空格
---

# 完全分布式安装配置

## 前提准备

### 首先需要准备配置jdk

见[伪分布式安装配置](https://zhuanlan.zhihu.com/p/491426016)

### ssh连接
我采用的是本地ssh连接

然后在根据给定的机器的ip和用户密码，连接全部机器

然后再user/local下查看jdk，如果有，就直接配置相关的配置，如果没有就需要手动下载jdk，然后再配置（三台机器都需要配置）
```sh
export JAVA_HOME=/usr/local/jdk1.8/
export JRE_HOME=/usr/local/jdk1.8/jre
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
```

```
source  /etc/profile
java -version
```
最后配置好查看每台机器的java -version

### 然后配置每台机器的免密登录

先检查三台节点的`etc/hosts`文件是否配置好，如下是配置好的状态

检查两台机器是否能ping通

随后在每台机器上使用`ssh-keygen -t rsa`命令生成公钥和私钥

随后操作slave1和slave2

```
scp /root/.ssh/id_rsa.pub  root@master:/root/.ssh/id_rsa.pub.slave1

scp /root/.ssh/id_rsa.pub  root@master:/root/.ssh/id_rsa.pub.slave2
```

然后回到master节点操作
随后将authorized_keys文件分发到slave1和slave2上
```
cd /root/.ssh

cat id_rsa.pub >> authorized_keys
cat id_rsa.pub.slave1 >> authorized_keys
cat id_rsa.pub.slave2 >> authorized_keys

```

```
#在master节点上执行名把authorized_keys文件拷贝到slave1和slave2上

scp /root/.ssh/authorized_keys root@slave1:/root/.ssh/authorized_keys
scp /root/.ssh/authorized_keys root@slave2:/root/.ssh/authorized_keys
```

最后测试免密登录
```
ssh master
ssh slave1
ssh slave2
```

## 安装配置Hadoop

# hadoop分布式安装

## 配置

先在master上配置，然后将配置和安装全部分发到从节点

### 配置hadoop-env.sh

```
# 进入文件
vi /usr/local/hadoop/etc/hadoop/hadoop-env.sh
# 将文件的JAVA_HOME路径更改为安装的路径（实际路径根据个人）
export JAVA_HOME=/usr/local/jdk1.8
```
### 配置core-site.xml

```xml
vi /usr/local/hadoop/etc/hadoop/core-site.xml
# 在<configuration>下添加如下配置
<property>
	<name>fs.defaultFS</name>
	<value>hdfs://master:9000</value>
	# 注意，此处的master是因为在之前配置了hosts
</property>
<property>
	<name>hadoop.tmp.dir</name>
	<value>/usr/local/hadoop/tmp</value>
</property>
```
### 配置hdfs-site.xm

```xml
vi /usr/local/hadoop/etc/hadoop/hdfs-site.xml
# 在<configuration>下添加如下配置
<property>
	<name>dfs.replication</name>
	<value>2</value>
        # 因为是两个从节点所以只需要两个数据副本数
</property>
<property>
	<name>dfs.permissions</name>
	<value>true</value>
</property>
```

### 配置yarn-site.xml

```xml
vi /usr/local/hadoop/etc/hadoop/yarn-site.xml
# 在<configuration>下添加如下配置
<property>
	<name>yarn.resourcemanager.hostname</name>
	<value>master</value>
</property>
<property>
	<name>yarn.nodemanager.aux-services</name>
	<value>mapreduce_shuffle</value>
</property>
```

### 配置slaves

```
vi /usr/local/hadoop/etc/hadoop/slaves
# 删除locallhost
#添加
slave1
slave2
```

## slave1&slave2

### 将master的安装和配置发送到从节点

```
# 发送给slave1
scp -r /usr/local/hadoop/etc/hadoop root@slave1:/usr/local/hadoop/etc
# 发送给slave2
scp -r /usr/local/hadoop/etc/hadoop root@slave2:/usr/local/hadoop/etc
```

### 配置Hadoop环境变量

```
vi /etc/profile
# 增加
export HADOOP_HOME=/usr/local/hadoop
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
# 使文件生效
source /etc/profile
```

> 需要三个节点都可以运行Hadoop命令，所以需要在三个节点都配置

## 启动

### 启动hdfs

```sh
start-dfs.sh
```

### 启动yarn

```sh
start-yarn.sh
```

### 在从节点上查看进程

```
# 在slave1上查看
jps
```

```
# 在slave2上查看
jps
```

除jps可以看到有5个进程，NameNode

### 在浏览器中查看

在浏览器中查看master节点的50070端口

`http://10.244.9.5:50070`地址根据个人情况更改


至此，Hadoop的安装配置完成

## 检验

测试命令
```
hadoop fs -ls /
hadoop fs -mkdir /test
hadoop fs -ls /
```
如下，就已经完成完全分布式的安装和配置
