# 航班数据统计求和

## 准备

数据格式 csv

```csv
Year,Month,DayofMonth,DayOfWeek.......
1999,1,27,3.....
```

本次实验统计 DayOfWeek，按照不同数值分类，并统计每个分类的总数

## 代码

### map类

获取数据，去除顶行数据，以及无用数据，然后分割取出需要的 DayOfWeek 数据，最后返回不同类型的数据

```java
public static class MapTask extends Mapper<Object, Text, Text, IntWritable>{
    private final static IntWritable Num = new IntWritable(1);
    private final Text txtKey = new Text();
    @Override
    protected void map(Object key, Text value, Context context)
            throws IOException, InterruptedException {
        String[] fields = value.toString().split(",");
        int score = 0;
        try {
            if(fields.length > 4)
                score = Integer.parseInt(fields[3]); //过滤掉顶层标题行，发生异常时直接结束本次map函数
        } catch (NumberFormatException e) {
            return;
        }

        String Type = "";
        if(score < 6)
            Type = "die";
        else if(score <= 7)
            Type = "6-7";
        else if(score <= 8)
            Type = "7-8";
        else if(score <= 9)
            Type = "8-9";
        else if(score <= 10)
            Type = "9-10";
        txtKey.set(Type);
        context.write(txtKey, Num);
    }
}
```

### reduce类

总和不同分类的数据

```java
public static class ReduceTask extends Reducer<Text, IntWritable, Text, IntWritable>{
    private final IntWritable result = new IntWritable();
    @Override
    protected void reduce(Text key, Iterable<IntWritable> values,
                          Context context) throws IOException, InterruptedException {
        int sum = 0;
        for (IntWritable val : values)  {
            sum += val.get();
        }
        result.set(sum);
        context.write(key, result);
    }
}
```

### main

```java
public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {
    System.setProperty("HADOOP_USER_NAME", "root");
    Configuration conf = new Configuration();
    conf.set("fs.defaultFS", "hdfs://master:9000");
    //1.MR由Job对象去提交任务
    Job job = Job.getInstance(conf);
    //2.告知job提交的信息
    job.setMapperClass(MapTask.class);
    job.setReducerClass(ReduceTask.class);
    job.setJarByClass(Sort.class);
    //3.告知MR，输出类型 （只需要设置输出类型）
    //map的输出
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(IntWritable.class);
    //reduce的输出
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);

    //4.输入输出文件的路径设置
    String output = "/bigdata/output/FightData/";
    //加一个判断
    FileSystem fileSystem = FileSystem.get(conf);
    if(fileSystem.exists(new Path(output))) {
        fileSystem.delete(new Path(output),true);
    }

    FileInputFormat.addInputPath(job, new Path("/bigdata/input/FightData/"));
    FileOutputFormat.setOutputPath(job, new Path(output));

    //为了测试
    boolean b = job.waitForCompletion(true);
    System.out.println(b ? "SUCCESS！！" : "FAIL");
}
```


## 结果

![](../../markdown_img/Pasted%20image%2020220905162632.png)