
# 二次排序

## 准备

创建文件，数据如下：

```txt
uid：用户id  
time：时间  
msg：发出消息内容
```

需求是先按 uid 排序，然后按 time 排序，显示发出消息  


```txt
uId time msg  
2 12:12:34 2_hello  
3 09:10:34 3_byby  
1 15:02:41 1_aaaaa  
3 22:11:34 3_bbbbbb  
1 19:10:34 1_cccccc  
2 15:02:41 2_dddddd  
1 12:12:34 1_eeeeeee  
3 23:10:34 3_fffffffff  
2 05:02:41 2_gggggg
```

## 分析

自定义数据类型，先按照uid从小到大进行排序，如果uid相等，按照时间排序


## 代码

### SecondSort类

```java
class SecondSort implements WritableComparable<SecondSort> {  
    private String uid;  
    private String time;  
  
    public SecondSort() {}  
  
    public SecondSort(String uid, String time) {  
        this.uid = uid;  
        this.time = time;  
    }  

    @Override  
    public int compareTo(SecondSort o) {  
        // 如果 uid 相同就比较 time        int temp = this.uid.compareTo(o.uid);  
        if (temp == 0) {  
            temp = this.time.compareTo(o.time);  
        }  
        return temp;  
    }  
  
    @Override  
    public void write(DataOutput dataOutput) throws IOException {  
        dataOutput.writeUTF(this.uid);  
        dataOutput.writeUTF(this.time);  
    }  
  
    @Override  
    public void readFields(DataInput dataInput) throws IOException {  
        this.uid = dataInput.readUTF();  
        this.time = dataInput.readUTF();  
    }  
  
    @Override  
    public String toString() {   // 输出格式
        return this.uid + "\t" + this.time;  
    }  
}  
```

### map

```java
public static class MapTask extends Mapper<LongWritable, Text, SecondSort, Text> {  
	@Override  
	protected void map(LongWritable key, Text value, Context context)  
			throws IOException, InterruptedException {  
		String[] fields = value.toString().split("\t");  
		if (fields.length < 3) {  
			return;  
		}  
		String uid = fields[0].trim();  
		String time = fields[1].trim();  
		String msg = fields[2].trim();  
		SecondSort ss = new SecondSort(uid, time);  
		context.write(ss, new Text(msg));  
	}  
}  
```

### reduce

```java
public static class ReduceTask extends Reducer<SecondSort, Text, SecondSort, Text>{  
	@Override  
	protected void reduce(SecondSort key, Iterable<Text> values, Context context)  
			throws IOException, InterruptedException {  
		for (Text val : values) {  
			context.write(key, val);  
		}  
	}  
}  
```


### main

```java
public class SecondarySort {  
    public static void main(String[] args) throws Exception{  
        //告诉系统运行的时候，使用root权限  
        System.setProperty("HADOOP_USER_NAME", "root");  
        Configuration conf = new Configuration();  
        conf.set("fs.defaultFS", "hdfs://master:9000");  
        //1.MR由Job对象去提交任务  
        Job job = Job.getInstance(conf);  
        //2.告知job提交的信息  
        job.setMapperClass(MapTask.class);  
        job.setReducerClass(ReduceTask.class);  
        job.setJarByClass(SecondarySort.class);  
        //3.告知MR，输出类型 （只需要设置输出类型）  
        //map的输出  
        job.setMapOutputKeyClass(SecondSort.class);  
        job.setMapOutputValueClass(Text.class);  
        //reduce的输出  
        job.setOutputKeyClass(SecondSort.class);  
        job.setOutputValueClass(Text.class);  
        //4.输入输出文件的路径设置  
        String output = "/bigdata/output/SecondSort/";  
        //加一个判断  
        FileSystem fileSystem = FileSystem.get(conf);  
        if (fileSystem.exists(new Path(output))) {  
            fileSystem.delete(new Path(output), true);  
        }  
        FileInputFormat.addInputPath(job, new Path("/bigdata/input/SecondSort/"));  
        FileOutputFormat.setOutputPath(job, new Path(output));  
        //为了测试  
        boolean b = job.waitForCompletion(true);  
        System.out.println(b ? "T" : "F");  
    }  
}
```

## 结果

![](http://www.droliz.cn/markdown_img/Pasted%20image%2020220908111224.png)